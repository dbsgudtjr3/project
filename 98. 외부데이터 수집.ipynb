{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분석 환경 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 모듈 불러오기\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from selenium import webdriver \n",
    "from functools import reduce\n",
    "\n",
    "# 경로 설정\n",
    "os.chdir(r\"C:\\Users\\GilseungAhn\\Desktop\\한양대\\3. 프로젝트\\2. 진행중인 과제\\포스트코로나 AI 챌린지\\데이터\\2. 외부데이터\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해외유입확진자 수 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탐색중인 게시판 번호: 1\n",
      "탐색중인 게시판 번호: 2\n",
      "탐색중인 게시판 번호: 3\n",
      "탐색중인 게시판 번호: 4\n",
      "탐색중인 게시판 번호: 5\n",
      "탐색중인 게시판 번호: 6\n",
      "탐색중인 게시판 번호: 7\n",
      "탐색중인 게시판 번호: 8\n",
      "탐색중인 게시판 번호: 9\n",
      "탐색중인 게시판 번호: 10\n",
      "탐색중인 게시판 번호: 11\n",
      "탐색중인 게시판 번호: 12\n",
      "탐색중인 게시판 번호: 13\n",
      "탐색중인 게시판 번호: 14\n",
      "탐색중인 게시판 번호: 15\n",
      "탐색중인 게시판 번호: 16\n",
      "탐색중인 게시판 번호: 17\n",
      "탐색중인 게시판 번호: 18\n",
      "탐색중인 게시판 번호: 19\n",
      "탐색중인 게시판 번호: 20\n",
      "탐색중인 게시판 번호: 21\n",
      "탐색중인 게시판 번호: 22\n",
      "탐색중인 게시판 번호: 23\n",
      "탐색중인 게시판 번호: 24\n",
      "탐색중인 게시판 번호: 25\n",
      "탐색중인 게시판 번호: 26\n",
      "탐색중인 게시판 번호: 27\n",
      "탐색중인 게시판 번호: 28\n",
      "탐색중인 게시판 번호: 29\n",
      "탐색중인 게시판 번호: 30\n"
     ]
    }
   ],
   "source": [
    "# 메인 url 설정 및 수집 결과 초기화\n",
    "main_url = 'https://www.cdc.go.kr'\n",
    "board_page_num = 1\n",
    "result_dic = dict() # key: 날짜, value: 누적해외유입확진자 수\n",
    "\n",
    "while True:\n",
    "    print(\"탐색중인 게시판 번호: {}\".format(board_page_num))\n",
    "    board_url = 'board.es?mid=a20501000000&bid=0015&nPage=' + str(board_page_num) # board_page_num번째 게시판 목록의 url\n",
    "    \n",
    "    # board_url에 해당하는 HTML 가져오기\n",
    "    board_response = requests.get(main_url + '/' + board_url)\n",
    "    board_text = board_response.text\n",
    "    \n",
    "    # 게시판에 등록된 열 개의 문서 가운데, 코로나 관련 기사가 한 건도 나오지 않으면, 탐색을 중지\n",
    "    if not('코로나바이러스감염증-19 국내 발생 현황' in board_text or '신종코로나바이러스감염증 국내 발생 현황' in board_text):\n",
    "        break\n",
    "    \n",
    "    # 게시판에 등장한 코로나 관련 기사의 링크 수집\n",
    "    content_tag_list = BS(board_text).find_all(\"li\", \"title\")[1:]\n",
    "    for content_tag in content_tag_list:\n",
    "        content_no = str(content_tag.find('a')['href']).split('list_no=')[1].split('&')[0] # 코로나 관련 기사 링크의 번호 (유니크한 ID 역할)\n",
    "        content_url = 'https://www.cdc.go.kr/board/board.es?mid=a20501000000&bid=0015&act=view&list_no=' + content_no\n",
    "        \n",
    "        # 코로나 관련 기사 가져오기\n",
    "        content_response = requests.get(content_url)                \n",
    "        content_text = content_response.text\n",
    "        \n",
    "        # 코로나 관련 기사에서 해외유입 정보 가져오기 및 저장\n",
    "        content_title = str(BS(content_text).find(\"meta\", attrs = {\"name\":\"title\"}))\n",
    "        \n",
    "        # 코로나바이러스감염증-19 국내 발생 현황 혹은 신종코로나바이러스감염증 국내 발생 현황이 문서 제목에 포함된 경우만 크롤링\n",
    "        if '코로나바이러스감염증-19 국내 발생 현황' in content_title or '신종코로나바이러스감염증 국내 발생 현황' in content_title:\n",
    "            \n",
    "            # 정례브리핑이 문서 제목에 포함되고, 해외유입이 문서 내용에 포함된 경우만 크롤링\n",
    "            if '정례브리핑' in content_title:\n",
    "                content_date = content_title.split('(')[1].split(',')[0]\n",
    "                if '해외유입' in content_text:\n",
    "                    try:                        \n",
    "                        # 수집 문구: ..., 총 누적 확진자수는 10,752명(해외유입 1,056명) ...에서 해외유입 **명\n",
    "                        content_num_definite_diagnosis = int(content_text.split(\"해외유입 \")[1].split('명')[0].replace(',', '')) # 천 명을 넘는 순간부터 콤마(,)가 붙어서 콤마를 제거\n",
    "                    except:\n",
    "                        content_num_definite_diagnosis = 0\n",
    "                \n",
    "                # 수집 결과 저장\n",
    "                if content_date not in result_dic.keys():\n",
    "                    result_dic[content_date] = content_num_definite_diagnosis                \n",
    "                time.sleep(1.5)                \n",
    "    board_page_num += 1\n",
    "\n",
    "# 수집한 데이터 자료형 변환 및 저장\n",
    "def convert_string_to_datetime(s): # M월 D일\n",
    "    year = 2020\n",
    "    month = int(s.split('월')[0])\n",
    "    day = int(s.split(' ')[1].split('일')[0])\n",
    "    return pd.Timestamp(year = year, month = month, day = day)\n",
    "\n",
    "# 수집 결과를 데이터 프레임 형태로 변환\n",
    "result_df = pd.DataFrame(result_dic.items(), columns = ['일자', '누적확진자'])\n",
    "\n",
    "# 일자 변수의 타입 변환 (string -> datetime)\n",
    "result_df['일자'] = result_df['일자'].apply(convert_string_to_datetime)\n",
    "\n",
    "# 일자 기준 정렬 및 데이터 내보내기 (일자별_누적해외유입확진자수.csv)\n",
    "result_df.sort_values(by = '일자', inplace = True)\n",
    "result_df.to_csv(\"일자별_누적해외유입확진자수.csv\", index = False, encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해외증시 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해외증시:니케이, 페이지번호:1\n",
      "해외증시:니케이, 페이지번호:2\n",
      "해외증시:니케이, 페이지번호:3\n",
      "해외증시:니케이, 페이지번호:4\n",
      "해외증시:니케이, 페이지번호:5\n",
      "해외증시:니케이, 페이지번호:6\n",
      "해외증시:니케이, 페이지번호:7\n",
      "해외증시:니케이, 페이지번호:8\n",
      "해외증시:니케이, 페이지번호:9\n",
      "해외증시:니케이, 페이지번호:10\n",
      "해외증시:다우산업, 페이지번호:1\n",
      "해외증시:다우산업, 페이지번호:2\n",
      "해외증시:다우산업, 페이지번호:3\n",
      "해외증시:다우산업, 페이지번호:4\n",
      "해외증시:다우산업, 페이지번호:5\n",
      "해외증시:다우산업, 페이지번호:6\n",
      "해외증시:다우산업, 페이지번호:7\n",
      "해외증시:다우산업, 페이지번호:8\n",
      "해외증시:다우산업, 페이지번호:9\n",
      "해외증시:다우산업, 페이지번호:10\n",
      "해외증시:S&P500, 페이지번호:1\n",
      "해외증시:S&P500, 페이지번호:2\n",
      "해외증시:S&P500, 페이지번호:3\n",
      "해외증시:S&P500, 페이지번호:4\n",
      "해외증시:S&P500, 페이지번호:5\n",
      "해외증시:S&P500, 페이지번호:6\n",
      "해외증시:S&P500, 페이지번호:7\n",
      "해외증시:S&P500, 페이지번호:8\n",
      "해외증시:S&P500, 페이지번호:9\n",
      "해외증시:S&P500, 페이지번호:10\n",
      "해외증시:상해종합, 페이지번호:1\n",
      "해외증시:상해종합, 페이지번호:2\n",
      "해외증시:상해종합, 페이지번호:3\n",
      "해외증시:상해종합, 페이지번호:4\n",
      "해외증시:상해종합, 페이지번호:5\n",
      "해외증시:상해종합, 페이지번호:6\n",
      "해외증시:상해종합, 페이지번호:7\n",
      "해외증시:상해종합, 페이지번호:8\n",
      "해외증시:상해종합, 페이지번호:9\n",
      "해외증시:상해종합, 페이지번호:10\n"
     ]
    }
   ],
   "source": [
    "# webdriver 구동하기 (반드시 chromedriver.exe가 설치되어 있어야 함)\n",
    "driver = webdriver.Chrome(r'C:\\Users\\GilseungAhn\\Desktop\\기타\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "# 수집대상 url 정의 및 수집 데이터 초기화\n",
    "url_dict = {\"니케이\":\"https://finance.naver.com/world/sise.nhn?symbol=NII@NI225#\",\n",
    "           \"다우산업\":\"https://finance.naver.com/world/sise.nhn?symbol=DJI@DJI\",\n",
    "           \"S&P500\":\"https://finance.naver.com/world/sise.nhn?symbol=SPI@SPX\",\n",
    "           \"상해종합\": \"https://finance.naver.com/world/sise.nhn?symbol=SHS@000001\"}\n",
    "\n",
    "# 결과를 저장할 리스트 (요소: 해외증시 데이터 (DataFrame))\n",
    "dfList = []\n",
    "\n",
    "for (url_id, url) in url_dict.items():\n",
    "    # url별 수집 데이터를 저장하는 사전 초기화 \n",
    "    result_dict = dict()\n",
    "    \n",
    "    # url 가져오기\n",
    "    driver.get(url)\n",
    "    \n",
    "    # 현재 날짜 기준 최대 max_page 페이지까지 수집 \n",
    "    max_page = 10 # 10페이지 이내에 분석 범위(2020년) 내 데이터가 모두 들어오므로 max_page를 10페이지로 설정\n",
    "    \n",
    "    for page_id in range(1, max_page + 1):\n",
    "        print(\"해외증시:{}, 페이지번호:{}\".format(url_id, page_id))\n",
    "        time.sleep(1.5)\n",
    "        \n",
    "        # 표 번호 (1 ~ max_page) 클릭\n",
    "        driver.find_element_by_id(\"dayLink\" + str(page_id)).click()\n",
    "        time.sleep(1.5)\n",
    "        \n",
    "        # dayTable: 해외증시가 있는 HTML 테이블\n",
    "        table = driver.find_element_by_id(\"dayTable\")\n",
    "        \n",
    "        # dayTable의 행을 기준으로 데이터 수집\n",
    "        for tr in table.find_elements_by_tag_name(\"tr\"):\n",
    "            try: # 해외 증시의 경우에는 공백(' ')으로 데이터가 구분되어 있음. 공백이 없는 데이터는 해외 증시 데이터가 아님.\n",
    "                date, value = tr.text.split(' ')[:2]                   \n",
    "                result_dict[date] = value       \n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "    # 증시별 수집 결과 저장 및 dfList에 추가\n",
    "    result_df = pd.DataFrame(result_dict.items(), columns = ['일자', url_id + \"지수\"])\n",
    "    result_df[url_id + \"지수\"] = result_df[url_id + \"지수\"].str.replace(',', '').astype(float)\n",
    "    dfList.append(result_df)\n",
    "\n",
    "# 해외증시 데이터 병합 (단, 지수별로 장이 안 열리는 날은 결측이 되어 있음)\n",
    "output_df = reduce(lambda x, y: pd.merge(x, y, on = '일자', how = 'outer'), dfList)    \n",
    "\n",
    "# 일자 변수의 타입 변환 (string -> datetime)\n",
    "output_df['일자'] = pd.to_datetime(output_df['일자'])    \n",
    "\n",
    "# 일자 기준 정렬 및 데이터 내보내기 (일자별_해외지수.csv)\n",
    "output_df.sort_values(by = '일자', inplace = True)\n",
    "output_df.to_csv(\"일자별_해외지수.csv\", index = False, encoding = \"utf8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
